{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "386jgs8vEg4y"
      },
      "source": [
        "# Description\n",
        "\n",
        "## This aim of this notbook to show and compare Contextual Retrieval implementation of RAG vs. simple/traditional implemintation\n",
        "### Steps:\n",
        "- Chucking\n",
        "- Summarization\n",
        "- BM25 embedding\n",
        "- BM25 model saving to file\n",
        "- Model embedding\n",
        "- Storage of dense and sparse vectors\n",
        "- Retrieval of sparse and dense vectors\n",
        "- Fusion of Ranking\n",
        "- Simple Retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i0rQp-2yE9tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f9a236-738a-42a5-c77b-afb382564c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip install sentence_transformers -qU\n",
        "!pip install rank_bm25 -qU\n",
        "!pip install datasets -qU\n",
        "# !pip install -U FlagEmbedding\n",
        "# !pip install pinecone-plugin-inference -qU\n",
        "!pip install pinecone[grpc] -qU\n",
        "# !pip install pinecone-client  -qU\n",
        "!pip install langchain -qU\n",
        "!pip install langchain_core -qU\n",
        "!pip install langchain_groq -qU\n",
        "!pip install langchain-google-genai -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install rouge-score  -qU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLvPphUjI1yb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7pHvMtoEg41"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oTin1IoFEg42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1492a30-9974-4364-bebb-315e9ae6e021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "# from rouge import Rouge\n",
        "from datasets import load_dataset\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import pinecone\n",
        "import pandas as pd # for dataframe\n",
        "import getpass\n",
        "from google.colab import userdata\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6Bv35qGcEg43"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVfN2cBE6rT",
        "outputId": "17fdf10a-f79a-4a1a-acb6-1b6b0083d510"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw1FTzkTEg44"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "f5602a797be045b6a025b732d7fd4239",
            "207784568862475286a2937769378f6d",
            "c1ad258a0ad24635b10c464550fe3e4f",
            "7664336b406b4551b5b6d286de592dbc",
            "f4483a2dbaad421cbe785820d3b0c7bd",
            "e9160ea16bd64a108bcd94aa8836ae67",
            "f5e531602d164991b20168d360c2819f",
            "d6c7c09ea507436eb3bb8b58d5389df6",
            "1d127fc274474d96ab3b8f0f46d5ec2d",
            "43d8e28fb7664439a99f3b4a7b062206",
            "63fbd3b86956469080dd49892c5ac715",
            "4ee735a3c0024663b3adc611163f8a33",
            "f29b4582df454f1cad766a147095fbb1",
            "1c4075de3c47470b933a194b937c5ac1",
            "6ab140d7c2fd4cf6ae7c1c0347d4cbe8",
            "a9507383300d447fadd2884d8086461e",
            "dd8e4d9b8b5043769baed08283ff81c8",
            "6e18cbcd4dc046d4b1a97215e5d95d4d",
            "880c9a3f43ed496bb78bd607904a7803",
            "127d4ef074b94b7e99fd631d9d0ea851",
            "36275140a3dc423a803dc375cf7eac52",
            "a2da143390f44e8aa91332046a2ee884",
            "07527b16c8ca4526b5bfdcd3ee8ad281",
            "ec11416e51a84a328fc29c2fdcab07d6",
            "4d9567829d3b4bf7a0deaca711211a95",
            "93efcf19123141289c2ea18cc021bfc2",
            "3ac2644a564a48549a060daae0f43461",
            "fb0c5d0d19954f01b133b0fc03dc203d",
            "f154d84958824a2289caef700fc4b976",
            "35936cdb3f93494b836647bbf828f9c1",
            "62652df54c6f4e88a31e2c63e5f2d085",
            "5640b1fa1bee41dfac05d91d1b5ae42c",
            "fc67f480e43e45adaec8828a5c43a521"
          ]
        },
        "id": "plaURsn2eFlM",
        "outputId": "a85478e0-0414-4b33-888d-d15190b088a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/893 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5602a797be045b6a025b732d7fd4239"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/289k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ee735a3c0024663b3adc611163f8a33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/65 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07527b16c8ca4526b5bfdcd3ee8ad281"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 1: Load and Chunk the Knowledge Base\n",
        "# Load dataset from Hugging Face\n",
        "\n",
        "dataset = load_dataset(\"m-ric/huggingface_doc_qa_eval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbXt0DzrEg44",
        "outputId": "607a5eaa-4850-451c-c20f-5ccea4cb79b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             context  \\\n",
            "0   `tokenizers-linux-x64-musl`\\n\\nThis is the **...   \n",
            "1  !--Copyright 2023 The HuggingFace Team. All ri...   \n",
            "2   Paper Pages\\n\\nPaper pages allow people to fi...   \n",
            "3   Datasets server API\\n\\n> API on 🤗 datasets\\n\\...   \n",
            "4  !--Copyright 2022 The HuggingFace Team. All ri...   \n",
            "\n",
            "                                            question  \\\n",
            "0  What architecture is the `tokenizers-linux-x64...   \n",
            "1  What is the purpose of the BLIP-Diffusion mode...   \n",
            "2  How can a user claim authorship of a paper on ...   \n",
            "3  What is the purpose of the /healthcheck endpoi...   \n",
            "4  What is the default context window size for Lo...   \n",
            "\n",
            "                                              answer  \\\n",
            "0                          x86_64-unknown-linux-musl   \n",
            "1  The BLIP-Diffusion model is designed for contr...   \n",
            "2  By clicking their name on the corresponding Pa...   \n",
            "3                          Ensure the app is running   \n",
            "4                                         127 tokens   \n",
            "\n",
            "                                          source_doc  standalone_score  \\\n",
            "0  huggingface/tokenizers/blob/main/bindings/node...                 5   \n",
            "1  huggingface/diffusers/blob/main/docs/source/en...                 5   \n",
            "2  huggingface/hub-docs/blob/main/docs/hub/paper-...                 5   \n",
            "3  huggingface/datasets-server/blob/main/services...                 5   \n",
            "4  huggingface/transformers/blob/main/docs/source...                 5   \n",
            "\n",
            "                                     standalone_eval  relatedness_score  \\\n",
            "0  The question is asking about the specific arch...                  5   \n",
            "1  The question is asking for the purpose of a sp...                  5   \n",
            "2  The question is clear and does not depend on a...                  5   \n",
            "3  The question is asking for the purpose of a sp...                  5   \n",
            "4  The question is asking for a specific paramete...                  5   \n",
            "\n",
            "                                    relatedness_eval  relevance_score  \\\n",
            "0  The context directly specifies the architectur...                3   \n",
            "1  The context provides a detailed description of...                3   \n",
            "2  The context provides a clear explanation of ho...                3   \n",
            "3  The context directly states the purpose of the...                4   \n",
            "4  The context provides a specific detail about t...                3   \n",
            "\n",
            "                                      relevance_eval  \n",
            "0  The question is asking for specific technical ...  \n",
            "1  The question asks about the purpose of the BLI...  \n",
            "2  The question is specific to the Hugging Face H...  \n",
            "3  The question is specific and technical, asking...  \n",
            "4  This question is specific and technical, askin...  \n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(dataset['train'])\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking only best question/answer pairs"
      ],
      "metadata": {
        "id": "DYMDunUnRZVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjRiBI5tEg45",
        "outputId": "bbe2205c-fd43-4cfd-8f30-b6d799de356f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             context  \\\n",
            "0   `tokenizers-linux-x64-musl`\\n\\nThis is the **...   \n",
            "1  !--Copyright 2023 The HuggingFace Team. All ri...   \n",
            "2   Paper Pages\\n\\nPaper pages allow people to fi...   \n",
            "3   Datasets server API\\n\\n> API on 🤗 datasets\\n\\...   \n",
            "4  !--Copyright 2022 The HuggingFace Team. All ri...   \n",
            "\n",
            "                                            question  \\\n",
            "0  What architecture is the `tokenizers-linux-x64...   \n",
            "1  What is the purpose of the BLIP-Diffusion mode...   \n",
            "2  How can a user claim authorship of a paper on ...   \n",
            "3  What is the purpose of the /healthcheck endpoi...   \n",
            "4  What is the default context window size for Lo...   \n",
            "\n",
            "                                              answer  \\\n",
            "0                          x86_64-unknown-linux-musl   \n",
            "1  The BLIP-Diffusion model is designed for contr...   \n",
            "2  By clicking their name on the corresponding Pa...   \n",
            "3                          Ensure the app is running   \n",
            "4                                         127 tokens   \n",
            "\n",
            "                                          source_doc  standalone_score  \\\n",
            "0  huggingface/tokenizers/blob/main/bindings/node...                 5   \n",
            "1  huggingface/diffusers/blob/main/docs/source/en...                 5   \n",
            "2  huggingface/hub-docs/blob/main/docs/hub/paper-...                 5   \n",
            "3  huggingface/datasets-server/blob/main/services...                 5   \n",
            "4  huggingface/transformers/blob/main/docs/source...                 5   \n",
            "\n",
            "                                     standalone_eval  relatedness_score  \\\n",
            "0  The question is asking about the specific arch...                  5   \n",
            "1  The question is asking for the purpose of a sp...                  5   \n",
            "2  The question is clear and does not depend on a...                  5   \n",
            "3  The question is asking for the purpose of a sp...                  5   \n",
            "4  The question is asking for a specific paramete...                  5   \n",
            "\n",
            "                                    relatedness_eval  relevance_score  \\\n",
            "0  The context directly specifies the architectur...                3   \n",
            "1  The context provides a detailed description of...                3   \n",
            "2  The context provides a clear explanation of ho...                3   \n",
            "3  The context directly states the purpose of the...                4   \n",
            "4  The context provides a specific detail about t...                3   \n",
            "\n",
            "                                      relevance_eval  \n",
            "0  The question is asking for specific technical ...  \n",
            "1  The question asks about the purpose of the BLI...  \n",
            "2  The question is specific to the Hugging Face H...  \n",
            "3  The question is specific and technical, asking...  \n",
            "4  This question is specific and technical, askin...  \n"
          ]
        }
      ],
      "source": [
        "best_answers_df = df[df['standalone_score'] >= 4]\n",
        "print(best_answers_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsJFVK-WEg45",
        "outputId": "338b54fa-2a2f-470f-9554-b65736a859b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 65 entries, 0 to 64\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   context            65 non-null     object\n",
            " 1   question           65 non-null     object\n",
            " 2   answer             65 non-null     object\n",
            " 3   source_doc         65 non-null     object\n",
            " 4   standalone_score   65 non-null     int64 \n",
            " 5   standalone_eval    65 non-null     object\n",
            " 6   relatedness_score  65 non-null     int64 \n",
            " 7   relatedness_eval   65 non-null     object\n",
            " 8   relevance_score    65 non-null     int64 \n",
            " 9   relevance_eval     65 non-null     object\n",
            "dtypes: int64(3), object(7)\n",
            "memory usage: 5.2+ KB\n"
          ]
        }
      ],
      "source": [
        "best_answers_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AU0Loz2Eg45"
      },
      "source": [
        "# Extract contexts from the dataset and create Langchain documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83Szf9dyEg46"
      },
      "outputs": [],
      "source": [
        "# Extract contexts from the dataset and create Langchain documents\n",
        "# documents = [Document(page_content=context) for context in best_answers_df['context']]  # Assuming we're using the 'train' split\n",
        "# print(documents)\n",
        "\n",
        "texts = best_answers_df['context'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting up Embedding model**"
      ],
      "metadata": {
        "id": "rZIDZI_PBYRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **sentence-transformers**"
      ],
      "metadata": {
        "id": "IMTkBRPrB2ce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK1mnOMPEg46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7610eb823dcb447b83c1f07d4e922c9b",
            "95ea3550d20f45b7a2402f59fd581e34",
            "ee9778ad21a14bfa92223cb6de4741b5",
            "b81a5e87e001431a926539b99bfab218",
            "df87fa25688b4ad0b72118ce661eac05",
            "76a99c20f17841fab64199faa2002154",
            "bb4c39c9a41c496498865e7f68924b77",
            "fee0a3d7436d4e7190213edbdb9c897f",
            "ed39c1c722d64fec8d89adadc72f6567",
            "50fd9a4eea954b5d9c75ed91ad4a89d6",
            "70584dbd70df495cb79be133338b14ba"
          ]
        },
        "outputId": "a3ebdcee-46e3-44e6-8ce2-7fc54fd065f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7610eb823dcb447b83c1f07d4e922c9b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # load ' sentence-transformers/all-MiniLM-L6-v2' embedding model from Hugging Face\n",
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# max_seq_length = tokenizer.model_max_length\n",
        "# embedding_model = AutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **openai**"
      ],
      "metadata": {
        "id": "k0aFEsYBYWT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not openai_api_key:\n",
        "  openai_api_key = getpass(\"Please enter your OPENAI API KEY: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "ICKWl98grnHR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "max_seq_length = embedding_model.embedding_ctx_length\n",
        "# index_dimensions = embedding_model.dimensions\n",
        "index_dimensions = 1536 # default setting of text-embedding-3-small\n",
        "print(f'max_seq_length:{max_seq_length}, index_dimensions:{index_dimensions}')"
      ],
      "metadata": {
        "id": "5HWee4hGYWBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e0715f-daac-40be-c3d0-14aea6a1c26d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_seq_length:8191, index_dimensions:1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Google**"
      ],
      "metadata": {
        "id": "5DsTq5PfB65i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# MODEL_GEMINI_EMBED = \"text-embedding-004\"\n",
        "# embedding_model = GoogleGenerativeAIEmbeddings(model=MODEL_GEMINI_EMBED)\n"
      ],
      "metadata": {
        "id": "RSyMWq7SByOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'max_seq_length:{max_seq_length}, index_dimensions:{index_dimensions}')"
      ],
      "metadata": {
        "id": "VmnVzxrxXFLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPrfhPe5Eg46"
      },
      "source": [
        "# Defining text splitter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###openai"
      ],
      "metadata": {
        "id": "4qoOMzEgntW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MARKDOWN_SEPARATORS = [\n",
        "    \"\\n#{1,6} \",\n",
        "    \"```\\n\",\n",
        "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "    \"\\n---+\\n\",\n",
        "    \"\\n___+\\n\",\n",
        "    \"\\n\\n\",\n",
        "    \"\\n\",\n",
        "    \" \",\n",
        "    \"\",\n",
        "]\n",
        "# Use RecursiveCharacterTextSplitter to split documents into chunks\n",
        "chunk_overlap = 200\n",
        "chunk_size = 1000 - chunk_overlap\n",
        "print('chunk_size',chunk_size)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separators=MARKDOWN_SEPARATORS,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwvXDlyQinuA",
        "outputId": "e45a4c5c-ac48-48ca-a324-abb196268937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk_size 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Other"
      ],
      "metadata": {
        "id": "-VTES-HCnx5m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_Xs4cIPEg46"
      },
      "outputs": [],
      "source": [
        "# def get_seq_length(text: str):\n",
        "#     tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "#     return len(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B3qr_EKEg47",
        "outputId": "792c2df8-2c88-414d-f3c3-a50a053693da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk_size 462\n"
          ]
        }
      ],
      "source": [
        "# MARKDOWN_SEPARATORS = [\n",
        "#     \"\\n#{1,6} \",\n",
        "#     \"```\\n\",\n",
        "#     \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "#     \"\\n---+\\n\",\n",
        "#     \"\\n___+\\n\",\n",
        "#     \"\\n\\n\",\n",
        "#     \"\\n\",\n",
        "#     \" \",\n",
        "#     \"\",\n",
        "# ]\n",
        "# # Use RecursiveCharacterTextSplitter to split documents into chunks\n",
        "# chunk_overlap = 50\n",
        "# chunk_size = max_seq_length - chunk_overlap\n",
        "# print('chunk_size',chunk_size)\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=chunk_size,\n",
        "#     chunk_overlap=chunk_overlap,\n",
        "#     length_function=get_seq_length,\n",
        "#     add_start_index=True,\n",
        "#     separators=MARKDOWN_SEPARATORS,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Definining ProcessedDocument & Chunk**"
      ],
      "metadata": {
        "id": "tWieWvZNSpZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flfZ4zNyEg47"
      },
      "outputs": [],
      "source": [
        "class Chunk:\n",
        "    def __init__(self, text: str):\n",
        "        self.text = text\n",
        "        self.context = None\n",
        "\n",
        "class ProcessedDocument:\n",
        "    def __init__(self, text: str, chunks: list[Chunk]):\n",
        "        self.text = text\n",
        "        self.chunks = chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x5T6XzSEg47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2d1e79-11aa-42ac-c4ab-7cbc5c6fef5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks for document #0: 1\n",
            "Number of chunks for document #1: 6\n",
            "Number of chunks for document #2: 5\n",
            "Number of chunks for document #3: 2\n",
            "Number of chunks for document #4: 12\n",
            "Number of chunks for document #5: 5\n",
            "Number of chunks for document #6: 29\n",
            "Number of chunks for document #7: 2\n",
            "Number of chunks for document #8: 40\n",
            "Number of chunks for document #9: 26\n",
            "Number of chunks for document #10: 5\n",
            "Number of chunks for document #11: 3\n",
            "Number of chunks for document #12: 16\n",
            "Number of chunks for document #13: 3\n",
            "Number of chunks for document #14: 7\n",
            "Number of chunks for document #15: 1\n",
            "Number of chunks for document #16: 22\n",
            "Number of chunks for document #17: 2\n",
            "Number of chunks for document #18: 20\n",
            "Number of chunks for document #19: 27\n",
            "Number of chunks for document #20: 24\n",
            "Number of chunks for document #21: 20\n",
            "Number of chunks for document #22: 40\n",
            "Number of chunks for document #23: 16\n",
            "Number of chunks for document #24: 1\n",
            "Number of chunks for document #25: 2\n",
            "Number of chunks for document #26: 12\n",
            "Number of chunks for document #27: 19\n",
            "Number of chunks for document #28: 5\n",
            "Number of chunks for document #29: 14\n",
            "Number of chunks for document #30: 2\n",
            "Number of chunks for document #31: 2\n",
            "Number of chunks for document #32: 8\n",
            "Number of chunks for document #33: 23\n",
            "Number of chunks for document #34: 5\n",
            "Number of chunks for document #35: 14\n",
            "Number of chunks for document #36: 7\n",
            "Number of chunks for document #37: 30\n",
            "Number of chunks for document #38: 3\n",
            "Number of chunks for document #39: 10\n",
            "Number of chunks for document #40: 1\n",
            "Number of chunks for document #41: 7\n",
            "Number of chunks for document #42: 12\n",
            "Number of chunks for document #43: 22\n",
            "Number of chunks for document #44: 28\n",
            "Number of chunks for document #45: 10\n",
            "Number of chunks for document #46: 11\n",
            "Number of chunks for document #47: 16\n",
            "Number of chunks for document #48: 2\n",
            "Number of chunks for document #49: 57\n",
            "Number of chunks for document #50: 12\n",
            "Number of chunks for document #51: 7\n",
            "Number of chunks for document #52: 50\n",
            "Number of chunks for document #53: 7\n",
            "Number of chunks for document #54: 24\n",
            "Number of chunks for document #55: 31\n",
            "Number of chunks for document #56: 6\n",
            "Number of chunks for document #57: 6\n",
            "Number of chunks for document #58: 3\n",
            "Number of chunks for document #59: 9\n",
            "Number of chunks for document #60: 11\n",
            "Number of chunks for document #61: 23\n",
            "Number of chunks for document #62: 24\n",
            "Number of chunks for document #63: 6\n",
            "Number of chunks for document #64: 6\n",
            "Number of Processed document: 65\n"
          ]
        }
      ],
      "source": [
        "docs_processed: list[ProcessedDocument] = []\n",
        "for text in texts:\n",
        "    # text = doc.page_content  # Extract the text content from the Document\n",
        "    chunks = text_splitter.split_text(text)  # Split the text into chunks (strings)\n",
        "    print(f\"Number of chunks for document #{len(docs_processed)}: {len(chunks)}\")\n",
        "    processed_doc = ProcessedDocument(\n",
        "        text,\n",
        "        [Chunk(chunk_text) for chunk_text in chunks]\n",
        "    )\n",
        "    docs_processed.append(processed_doc)\n",
        "print(f\"Number of Processed document: {len(docs_processed)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for doc in docs_processed:\n",
        "#     for chunk in doc.chunks:\n",
        "#         try:\n",
        "#           chunk_length = get_seq_length(chunk.text)\n",
        "#           if chunk_length > max_seq_length:\n",
        "#               print(f\"Chunk exceeds max length: {chunk_length} tokens\")\n",
        "#         except Exception as e:\n",
        "#           print(f\"Error processing chunk: {e}\")\n",
        "#           print(\"===========================\")\n",
        "#           print(f\"Chunk: {chunk.text}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uGPIkqc2hJGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqD1CrhoEg47",
        "outputId": "3d561f57-348c-4638-ee0a-aee0919fa8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of chunks across all documents: 882\n"
          ]
        }
      ],
      "source": [
        "# Count total chunks\n",
        "total_chunks = sum(len(doc.chunks) for doc in docs_processed)\n",
        "print(f\"Total number of chunks across all documents: {total_chunks}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xbm1paDEg47"
      },
      "source": [
        "# **Define summary chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "luOsyyoyEg47"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPENAI**"
      ],
      "metadata": {
        "id": "w3GPArSFTk-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "model_chat_name = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model=model_chat_name)\n",
        "sum_provider = 'OPENAI'"
      ],
      "metadata": {
        "id": "6tG8KcGJfTn-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "            \"\"\"You are an AI assistant specializing in document summarization and contextualization. Your task is to provide brief, relevant context for a specific chunk of text based on a larger document. Here's how to proceed:\n",
        "\n",
        "First, carefully read and analyze the following document:\n",
        "\n",
        "<document>\n",
        "{document}\n",
        "</document>\n",
        "\n",
        "Now, consider this specific chunk of text from the document:\n",
        "\n",
        "<chunk>\n",
        "{chunk}\n",
        "</chunk>\n",
        "\n",
        "Your goal is to provide a concise context for this chunk, situating it within the whole document. Follow these guidelines:\n",
        "\n",
        "1. Analyze how the chunk relates to the overall document's themes, arguments, or narrative.\n",
        "2. Identify the chunk's role or significance within the broader context of the document.\n",
        "3. Determine what information from the rest of the document is most relevant to understanding this chunk.\n",
        "\n",
        "Compose your response as follows:\n",
        "- Provide 3-4 sentences maximum of context.\n",
        "- Begin directly with the context, without any introductory phrases.\n",
        "- Use language like \"Focuses on...\" or \"Addresses...\" to describe the chunk's content.\n",
        "- Ensure the context would be helpful for improving search retrieval of the chunk.\n",
        "\n",
        "Important notes:\n",
        "- Do not use phrases like \"this chunk\" or \"this section\" in your response.\n",
        "- Do not repeat the chunk's content verbatim; provide context from the rest of the document.\n",
        "- Avoid unnecessary details; be succinct and relevant.\n",
        "- Do not include any additional commentary or meta-discussion about the task itself.\n",
        "\n",
        " Remember, your goal is to provide clear, concise, and relevant context that situates the given chunk within the larger document.\n",
        "            \"\"\"\n",
        "\n",
        "     )\n",
        "])\n"
      ],
      "metadata": {
        "id": "ZZMKgGuo6-Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_context_chain(llm):\n",
        "    return prompt_template | llm\n",
        "\n",
        "context_chain = create_context_chain(llm)"
      ],
      "metadata": {
        "id": "jYWgK3T5sumI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_context(text: str, chunk: str) -> str:\n",
        "    if len(chunk.strip()) <= 0 or len(text.strip()) <= 0:\n",
        "        print(f\"Chunk or text is empty\")\n",
        "        raise Exception(\"Chunk or text is empty\")\n",
        "    context= context_chain.invoke({\"document\": text, \"chunk\": chunk})\n",
        "    return context.content"
      ],
      "metadata": {
        "id": "8nNSuI3vtJjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_context(docs_processed: list[ProcessedDocument]):\n",
        "    for i, doc in enumerate(docs_processed):\n",
        "        print(f'processing document index {i}')\n",
        "        for chunk in doc.chunks:\n",
        "            # print(chunk.text)\n",
        "            context: str = get_context(text= doc.text, chunk= chunk.text)\n",
        "            chunk.context = context\n",
        "            # print(f\"chunk with context: Context: \\n\\n {chunk.context} \\n\\n Chunk: {chunk.text}\")"
      ],
      "metadata": {
        "id": "NVzI3sOHty8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing chain**"
      ],
      "metadata": {
        "id": "3Zu6dnWfiejY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page = \"\"\"\n",
        " Convert weights to safetensors\n",
        "\n",
        "PyTorch model weights are commonly saved and stored as `.bin` files with Python's [`pickle`](https://docs.python.org/3/library/pickle.html) utility. To save and store your model weights in the more secure `safetensor` format, we recommend converting your weights to `.safetensors`.\n",
        "The easiest way to convert your model weights is to use the [Convert Space](https://huggingface.co/spaces/diffusers/convert), given your model weights are already stored on the Hub. The Convert Space downloads the pickled weights, converts them, and opens a Pull Request to upload the newly converted `.safetensors` file to your repository.\n",
        "<Tip warning={true}>\n",
        "For larger models, the Space may be a bit slower because its resources are tied up in converting other models. You can also try running the [convert.py](https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py) script (this is what the Space is running) locally to convert your weights.\n",
        "Feel free to ping [@Narsil](https://huggingface.co/Narsil) for any issues with the Space.\n",
        "</Tip>\n",
        "\"\"\"\n",
        "chunk = \"\"\"\n",
        "Convert weights to safetensors\n",
        "PyTorch model weights are commonly saved and stored as `.bin` files with Python's [`pickle`](https://docs.python.org/3/library/pickle.html) utility. To save and store your model weights in the more secure `safetensor` format, we recommend converting your weights to `.safetensors`.\n",
        "The easiest way to convert your model weights is to use the [Convert Space](https://huggingface.co/spaces/diffusers/convert), given your model weights are already stored on the Hub. The Convert Space downloads the pickled weights, converts them, and opens a Pull Request to upload the newly converted `.safetensors` file to your repository.\n",
        "<Tip warning={true}>\n",
        "For larger models, the Space may be a bit slower because its resources are tied up in converting other models. You can also try running the [convert.py](https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py) script (this is what the Space is running) locally to convert your weights.\n",
        "Feel free to ping [@Narsil](https://huggingface.co/Narsil) for any issues with the Space.\n",
        "</Tip>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WYcumeIViZVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_context = get_context(text = page, chunk=chunk)"
      ],
      "metadata": {
        "id": "fdfaYjOPiiCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSpE3zdj5ni",
        "outputId": "70de0aaf-6dfb-40e0-d468-3532faa03cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document discusses converting PyTorch model weights saved as `.bin` files with `pickle` to a more secure `safetensor` format by using the Convert Space tool or running a conversion script locally. It emphasizes the importance of converting weights to `.safetensors` for security reasons. Additionally, the document provides a tip about potential delays in using the Convert Space tool due to resource constraints and offers an alternative method for conversion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temp_docs = docs_processed[1:2]\n",
        "# generate_context(temp_docs)\n",
        "generate_context(docs_processed)"
      ],
      "metadata": {
        "id": "Gp70kmKdwWae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6584a79-5e82-43fe-9efe-3481ae69cdad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing document index 0\n",
            "processing document index 1\n",
            "processing document index 2\n",
            "processing document index 3\n",
            "processing document index 4\n",
            "processing document index 5\n",
            "processing document index 6\n",
            "processing document index 7\n",
            "processing document index 8\n",
            "processing document index 9\n",
            "processing document index 10\n",
            "processing document index 11\n",
            "processing document index 12\n",
            "processing document index 13\n",
            "processing document index 14\n",
            "processing document index 15\n",
            "processing document index 16\n",
            "processing document index 17\n",
            "processing document index 18\n",
            "processing document index 19\n",
            "processing document index 20\n",
            "processing document index 21\n",
            "processing document index 22\n",
            "processing document index 23\n",
            "processing document index 24\n",
            "processing document index 25\n",
            "processing document index 26\n",
            "processing document index 27\n",
            "processing document index 28\n",
            "processing document index 29\n",
            "processing document index 30\n",
            "processing document index 31\n",
            "processing document index 32\n",
            "processing document index 33\n",
            "processing document index 34\n",
            "processing document index 35\n",
            "processing document index 36\n",
            "processing document index 37\n",
            "processing document index 38\n",
            "processing document index 39\n",
            "processing document index 40\n",
            "processing document index 41\n",
            "processing document index 42\n",
            "processing document index 43\n",
            "processing document index 44\n",
            "processing document index 45\n",
            "processing document index 46\n",
            "processing document index 47\n",
            "processing document index 48\n",
            "processing document index 49\n",
            "processing document index 50\n",
            "processing document index 51\n",
            "processing document index 52\n",
            "processing document index 53\n",
            "processing document index 54\n",
            "processing document index 55\n",
            "processing document index 56\n",
            "processing document index 57\n",
            "processing document index 58\n",
            "processing document index 59\n",
            "processing document index 60\n",
            "processing document index 61\n",
            "processing document index 62\n",
            "processing document index 63\n",
            "processing document index 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(temp_docs[0].chunks[0].context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3nF5jzIr-1p",
        "outputId": "3fd6b3e8-54cd-4f04-a753-8c1f49d5d430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GROQ**"
      ],
      "metadata": {
        "id": "NZPBwmbjThSx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZw6QTXGEg47"
      },
      "outputs": [],
      "source": [
        "# from pydantic import BaseModel, Field\n",
        "# from typing import Optional\n",
        "# class Context(BaseModel):\n",
        "#     context: Optional[str] = Field(description=\"Summary of the chunk in the context of the document\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4cmkTG6Eg48"
      },
      "outputs": [],
      "source": [
        "#It hits the limit even thoug lower than daily\n",
        "# from langchain_groq import ChatGroq\n",
        "\n",
        "# # MODEL_GROQ = \"llama-3.1-8b-instant\"\n",
        "# MODEL_GROQ = \"llama-3.2-90b-text-preview\"\n",
        "# groq_api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "# if not groq_api_key:\n",
        "#   groq_api_key = getpass(\"Please enter your GROQ API KEY: \")\n",
        "\n",
        "# llm = ChatGroq(api_key=groq_api_key, model=MODEL_GROQ,\n",
        "#                         temperature=0,\n",
        "#                         max_tokens=None,\n",
        "#                         timeout=None,\n",
        "#                         max_retries=2,)\n",
        "# sum_provider = 'GROQ'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GOOGLE**"
      ],
      "metadata": {
        "id": "mQXquYWATr5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL_GEMINI_CHAT = \"gemini-1.5-flash\"\n",
        "\n",
        "# gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "# if not gemini_api_key:\n",
        "#   gemini_api_key = getpass(\"Please enter your GEMINI API KEY: \")\n",
        "\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key"
      ],
      "metadata": {
        "id": "MJwYKKvVJhX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_google_genai import GoogleGenerativeAI\n",
        "# llm = GoogleGenerativeAI(model=MODEL_GEMINI_CHAT)\n",
        "# sum_provider = 'GOOGLE'"
      ],
      "metadata": {
        "id": "cGaEATOoTvaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0ZaOjQlEg48"
      },
      "outputs": [],
      "source": [
        "# prompt_template = PromptTemplate(\n",
        "#     input_variables=[\"document\", \"chunk\"],\n",
        "#     template=\n",
        "#        \"\"\"You are an AI assistant specializing in document summarization and contextualization. Your task is to provide brief, relevant context for a specific chunk of text based on a larger document. Here's how to proceed:\n",
        "\n",
        "# First, carefully read and analyze the following document:\n",
        "\n",
        "# <document>\n",
        "# {{DOCUMENT}}\n",
        "# </document>\n",
        "\n",
        "# Now, consider this specific chunk of text from the document:\n",
        "\n",
        "# <chunk>\n",
        "# {{CHUNK}}\n",
        "# </chunk>\n",
        "\n",
        "# Your goal is to provide a concise context for this chunk, situating it within the whole document. Follow these guidelines:\n",
        "\n",
        "# 1. Analyze how the chunk relates to the overall document's themes, arguments, or narrative.\n",
        "# 2. Identify the chunk's role or significance within the broader context of the document.\n",
        "# 3. Determine what information from the rest of the document is most relevant to understanding this chunk.\n",
        "\n",
        "# Compose your response as follows:\n",
        "# - Provide 3-4 sentences maximum of context.\n",
        "# - Begin directly with the context, without any introductory phrases.\n",
        "# - Use language like \"Focuses on...\" or \"Addresses...\" to describe the chunk's content.\n",
        "# - Ensure the context would be helpful for improving search retrieval of the chunk.\n",
        "\n",
        "# Important notes:\n",
        "# - Do not use phrases like \"this chunk\" or \"this section\" in your response.\n",
        "# - Do not repeat the chunk's content verbatim; provide context from the rest of the document.\n",
        "# - Avoid unnecessary details; be succinct and relevant.\n",
        "# - Do not include any additional commentary or meta-discussion about the task itself.\n",
        "\n",
        "#  Remember, your goal is to provide clear, concise, and relevant context that situates the given chunk within the larger document.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_context_chain(llm, structure: bool = True):\n",
        "#     # Configure the LLM to produce structured output\n",
        "#     if structure:\n",
        "#         l_llm = llm.with_structured_output(Context)\n",
        "#     else:\n",
        "#         l_llm = llm\n",
        "#     # Create the chain using the pipe operator\n",
        "#     chain = prompt_template | l_llm\n",
        "#     return chain\n",
        "\n",
        "# context_chain = create_context_chain(llm, structure = False)"
      ],
      "metadata": {
        "id": "P3AbgK_z7RM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHIhi0RWWq0z",
        "outputId": "84d6317e-9d01-4a2f-c311-958cc028b0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page:\n",
            "  Convert weights to safetensors\n",
            "\n",
            "PyTorch model weights are commonly saved and stored as `.bin` files with Python's [`pickle`](https://docs.python.org/3/library/pickle.html) utility. To save and store your model weights in the more secure `safetensor` format, we recommend converting your weights to `.safetensors`.\n",
            "\n",
            "The easiest way to convert your model weights is to use the [Convert Space](https://huggingface.co/spaces/diffusers/convert), given your model weights are already stored on the Hub. The Convert Space downloads the pickled weights, converts them, and opens a Pull Request to upload the newly converted `.safetensors` file to your repository.\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "For larger models, the Space may be a bit slower because its resources are tied up in converting other models. You can also try running the [convert.py](https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py) script (this is what the Space is running) locally to convert your weights.\n",
            "\n",
            "Feel free to ping [@Narsil](https://huggingface.co/Narsil) for any issues with the Space.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "chunk:\n",
            " Convert weights to safetensors\n",
            "\n",
            "PyTorch model weights are commonly saved and stored as `.bin` files with Python's [`pickle`](https://docs.python.org/3/library/pickle.html) utility. To save and store your model weights in the more secure `safetensor` format, we recommend converting your weights to `.safetensors`.\n",
            "\n",
            "The easiest way to convert your model weights is to use the [Convert Space](https://huggingface.co/spaces/diffusers/convert), given your model weights are already stored on the Hub. The Convert Space downloads the pickled weights, converts them, and opens a Pull Request to upload the newly converted `.safetensors` file to your repository.\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "For larger models, the Space may be a bit slower because its resources are tied up in converting other models. You can also try running the [convert.py](https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py) script (this is what the Space is running) locally to convert your weights.\n",
            "\n",
            "Feel free to ping [@Narsil](https://huggingface.co/Narsil) for any issues with the Space.\n",
            "\n",
            "</Tip>\n"
          ]
        }
      ],
      "source": [
        "# doc = docs_processed[30]\n",
        "# print(\"page:\\n\",doc.document.page_content)\n",
        "# # for chunk in doc.chunks:\n",
        "# chunk = doc.chunks[0]\n",
        "# print('chunk:\\n', chunk.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1poXgNkCWMxL"
      },
      "outputs": [],
      "source": [
        "# def get_context(doc: ProcessedDocument, chunk: Chunk, provider: str):\n",
        "#   if (provider == 'OPEMAI')\n",
        "#     context= context_chain.invoke({\"document\": doc.document.page_content, \"chunk\": chunk})\n",
        "#     return context.content\n",
        "#   else:\n",
        "#     context: Context = context_chain.invoke({\"document\": doc.document.page_content, \"chunk\": chunk})\n",
        "#     return context.context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLtidzjsaMU5"
      },
      "outputs": [],
      "source": [
        "# print(f\"chunk with context: Context: \\n\\n {context.context} \\n\\n Chunk: {chunk.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdEg5IDqJoWe"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# from datetime import datetime\n",
        "\n",
        "# def generate_context(docs_processed: list[ProcessedDocument]):\n",
        "#     # Initialize counters\n",
        "#     calls_per_minute = 0\n",
        "#     last_reset_time = time.time()\n",
        "\n",
        "#     for doc in docs_processed:\n",
        "#         for chunk in doc.chunks:\n",
        "#             current_time = time.time()\n",
        "\n",
        "#             # Check if a minute has passed since last reset\n",
        "#             if current_time - last_reset_time >= 60:\n",
        "#                 print(f\"Made {calls_per_minute} calls in the last minute\")\n",
        "#                 calls_per_minute = 0\n",
        "#                 last_reset_time = current_time\n",
        "#             else:\n",
        "#                 # If we're still within the same minute and hit rate limit\n",
        "#                 if calls_per_minute >= 15:  # Assuming 30 calls per minute limit\n",
        "#                     wait_time = 60 - (current_time - last_reset_time)\n",
        "#                     print(f\"Rate limit reached. Waiting {wait_time:.2f} seconds...\")\n",
        "#                     time.sleep(wait_time)\n",
        "#                     calls_per_minute = 0\n",
        "#                     last_reset_time = time.time()\n",
        "\n",
        "#             # Make the API call\n",
        "#             context: str = get_context(doc= doc.document.page_content, chunk= chunk, provider=???)\n",
        "#             doc.context = context.context\n",
        "\n",
        "#             # Increment counter\n",
        "#             calls_per_minute += 1\n",
        "\n",
        "#             # Optional: print progress\n",
        "#             print(f\"Processed chunk {calls_per_minute} in current minute. Total chunks processed: {sum(len(d.chunks) for d in docs_processed[:docs_processed.index(doc)]) + len(doc.chunks[:doc.chunks.index(chunk) + 1])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdmYQMFReFlR"
      },
      "source": [
        "## Save processed documents to file\n",
        "## Downloading processed documents in case notebook times out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivDZpzZMeFlR"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def save_download_object(object, filename):\n",
        "    joblib.dump(object, filename)\n",
        "    print(f\"Saved object to {filename}\")\n",
        "    files.download(filename)\n",
        "    print(f\"Downloaded {filename}\")\n",
        "\n",
        "def create_timestamp() -> str:\n",
        "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def create_filename_timestamp(filename, extension = \"joblib\") -> str:\n",
        "    timestamp = create_timestamp()\n",
        "    return f\"{filename}_{timestamp}.{extension}\"\n",
        "\n",
        "# def load_bm25_model(filename):\n",
        "#     try:\n",
        "#         return joblib.load(filename)\n",
        "#     except (FileNotFoundError, OSError):\n",
        "#         return None\n",
        "\n",
        "# def get_latest_bm25_file():\n",
        "#     # Look for files matching the pattern bm25_*.joblib\n",
        "#     files = glob.glob(\"bm25_*.joblib\")\n",
        "#     if not files:\n",
        "#         return None\n",
        "#     # Return the most recent file\n",
        "#     return max(files, key=os.path.getctime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-GbvORIeFlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9e3fd2ed-3b07-44bf-956d-7919208e21bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved object to docs_processed_20241203_134704.joblib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24d8ec34-2168-45ea-8943-551dc14ea4d6\", \"docs_processed_20241203_134704.joblib\", 1516267)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded docs_processed_20241203_134704.joblib\n"
          ]
        }
      ],
      "source": [
        "# Create filename with timestamp\n",
        "docs_processed_filename = create_filename_timestamp(\"docs_processed\")\n",
        "\n",
        "# Save the processed documents\n",
        "save_download_object(docs_processed, docs_processed_filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_texts = []\n",
        "document_texts = []\n",
        "contexts = []\n",
        "\n",
        "# Extract data from docs_processed\n",
        "for doc in docs_processed:\n",
        "    for chunk in doc.chunks:\n",
        "        chunk_texts.append(chunk.text)\n",
        "        contexts.append(chunk.context)\n",
        "        document_texts.append(doc.text)\n",
        "\n",
        "# Create dictionary for dataset\n",
        "dataset_dict = {\n",
        "    'chunk': chunk_texts,\n",
        "    'document': document_texts,\n",
        "    'context': contexts\n",
        "}"
      ],
      "metadata": {
        "id": "hUg5zY3egqtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_doc = 2\n",
        "doc = docs_processed[index_doc]\n",
        "print('len(doc.chuncks)',len(doc.chunks))\n",
        "chunk = doc.chunks[index_doc]\n",
        "print(chunk.context)\n",
        "# print('len(doc.chunks)',len(doc.chunks))\n",
        "# print(doc.chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG-24TTRp04r",
        "outputId": "c8bc838f-87b3-42cb-f8f6-98ddde7471f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(doc.chuncks) 5\n",
            "Focuses on the process of claiming authorship to a paper within the Hugging Face Hub, where the system tries to match papers to users based on their email addresses. Users can manually claim authorship by clicking on their name on the corresponding Paper page and following the steps to validate the request. Once approved by the admin team, the Paper page will be marked as verified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "print('len(contexts)',len(contexts))\n",
        "print(contexts[index])\n",
        "print('len(chunk_texts)',len(chunk_texts))\n",
        "print(chunk_texts[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da3vayJcg2HA",
        "outputId": "fd9b13b1-e751-42bc-ccea-c3c0407defb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(contexts) 882\n",
            "None\n",
            "len(chunk_texts) 882\n",
            "*Subject-driven text-to-image generation models create novel renditions of an input subject based on text prompts. Existing models suffer from lengthy fine-tuning and difficulties preserving the subject fidelity. To overcome these limitations, we introduce BLIP-Diffusion, a new subject-driven image generation model that supports multimodal control which consumes inputs of subject images and text prompts. Unlike other subject-driven generation models, BLIP-Diffusion introduces a new multimodal encoder which is pre-trained to provide subject representation. We first pre-train the multimodal encoder following BLIP-2 to produce visual representation aligned with the text. Then we design a subject representation learning task which enables a diffusion model to leverage such visual\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving Context + Chunks to dataset**"
      ],
      "metadata": {
        "id": "RPLQLJzxvv3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiCoPuZOEg48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "9241444d88c844e2a97676d935765b49",
            "14071b0512b94c3181e53db7b3a35202",
            "88582e22f86944e8a9d2e7dc853faf04",
            "a12cc0c4e5884849b2e444a6d0b4406b",
            "bf8c9017c3184fb2866cc648214ed5ca",
            "af9fc53cbd414753a7fa4043889b70d9",
            "54f70b15dbef48ee965499b73b3ab6e6",
            "1a17c06c44aa47968f7a53b27c6629c3",
            "e8c018602232414f8b11f582f0f521d6",
            "9a81a45162774028a2f354c7dc01db9c",
            "591704ad35224966b086db29df777f07",
            "0bbfc32869ed4774a7f6ccc10b27c5cc",
            "f38a0ff551b24dfc8ebc98ec9b0666eb",
            "81773f9406fa4975ad238e82357e1b89",
            "86ddfc36ed5b4999a8c908eee6096754",
            "3e5a5f41c3144d36853ed4d1b68544c5",
            "6ed6f3b38503478e9cf614c8a17702c5",
            "1cbb00e355c94d5a976b27a138cba919",
            "dd3b0e6739024d639b47428237c7db24",
            "788b2295dbe540728fa17fd58b6725dc",
            "cad2f57aab3c456f8e83ca4a7c619787",
            "e4d679ad02d9456badd82efe18b50f57"
          ]
        },
        "outputId": "b65b3508-b6ad-45ad-8aa0-1bbdbe8e06c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9241444d88c844e2a97676d935765b49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bbfc32869ed4774a7f6ccc10b27c5cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/AIEnthusiast369/hf_doc_qa_eval_chunk_size_800_open_ai/commit/7be3854af236da891ed8ecbd7299e0c9f0a3299a', commit_message='Upload dataset', commit_description='', oid='7be3854af236da891ed8ecbd7299e0c9f0a3299a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/AIEnthusiast369/hf_doc_qa_eval_chunk_size_800_open_ai', endpoint='https://huggingface.co', repo_type='dataset', repo_id='AIEnthusiast369/hf_doc_qa_eval_chunk_size_800_open_ai'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Create lists to store the data\n",
        "\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "hf_token = userdata.get(\"HuggingFace\")\n",
        "if not hf_token:\n",
        "  # Login to Hugging Face (you'll need your token)\n",
        "  hf_token = input(\"Please enter your Hugging Face token: \")\n",
        "login(hf_token)\n",
        "\n",
        "# Push to Hugging Face Hub\n",
        "dataset.push_to_hub(\n",
        "    f\"AIEnthusiast369/hf_doc_qa_eval_chunk_size_{chunk_size}_open_ai\",  # Replace with your username and desired dataset name\n",
        "    private=False  # Set to False if you want it public\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IsJEauoKkxp"
      },
      "outputs": [],
      "source": [
        "# prompt: print chunks from docs_processed where context has value\n",
        "\n",
        "# for doc in docs_processed:\n",
        "#   for chunk in doc.chunks:\n",
        "#     if chunk.context:\n",
        "#       print(f\"chunk with context: Context: \\n\\n {chunk.context} \\n\\n Chunk: {chunk.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading chunks with context dataset**\n",
        "*Yuu need to run it only in case of notebook timing out and you loose state*"
      ],
      "metadata": {
        "id": "AA6NpBJByPd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_dataset = load_dataset(\"AIEnthusiast369/hf_doc_qa_eval_chunk_size_800_open_ai\")\n",
        "chunks_from_ds=True"
      ],
      "metadata": {
        "id": "uPpFs15VyH0i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8702996f07724f8db48ea84ccb75bc2e",
            "0c475b51eaf94f38b47807c24ad4474d",
            "6db74a9354d64ca0b7cdf9f5739fed75",
            "e8af6213dd9f4384ba8abd36ce43797e",
            "3982f06b62c24f93b7c5c955d779a5c1",
            "70e9ad3287864c1da32ecfd9eb8c599c",
            "6b709b9213ae4c82908b54a9258a2c96",
            "e0c5487a349e43f79eb8d4de576bb9eb",
            "23529e6fc5304298bb1573272cd06c6c",
            "e57e462062de41d69c07e180ba4261f2",
            "2416240337ff450a964ef2f153782483",
            "32c58fa32a2840e4914134434c37b665",
            "482fc3846d4d4eb39e5f95d98f53f61b",
            "23d1f1fee552402498202007d6256778",
            "ae5e640938e04d3d8e0d705992d3693d",
            "78676885d1b6420e88076e78c2dfd32c",
            "09aa0733f352465599c98e2dd7406527",
            "1b9aec97b3d24cb7a8dae21d9b7b268d",
            "ce4e81ca5fbd41fe9cbf7245a7d59911",
            "c54dcff8598c4592a4abf10b9aec62cf",
            "e1c1618d4772498d8b0ecdf912dea553",
            "32a48a35a83841f58fb12740c24ed46e",
            "f893a601d4254cf18767503126dbafb5",
            "471d533d1b6e4e5a98c61259dec39445",
            "c916d773283d4b558fd3201c5f9346eb",
            "1b9b6a37b02f480fb09dfc354010aafb",
            "bc2f5660010a4c109254e18c39b5c818",
            "4a62108eaaf74204bbf6f5f46c337577",
            "1ec8c6fc4fd94f1785a991a485908f45",
            "098c36a685594b859e83e3b3e094ddde",
            "76072dfd0ad94175b53234ce8b40f229",
            "12aa1dbf3ee7428e974f8cb890487af0",
            "4175c196332a4f74abb57e2899a62fdc"
          ]
        },
        "outputId": "67fdd0e3-19e9-4c93-f261-aba6175cbaba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/348 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8702996f07724f8db48ea84ccb75bc2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/659k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32c58fa32a2840e4914134434c37b665"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/882 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f893a601d4254cf18767503126dbafb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating contextualized chunks**"
      ],
      "metadata": {
        "id": "6e7x0MetgiFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from multiprocessing import context\n",
        "# prompt: from chunked_dataset populate docs_processed\n",
        "\n",
        "# Assuming 'chunked_dataset' is already loaded as in your provided code\n",
        "chunks_with_context = []\n",
        "chunks_regular=[]\n",
        "\n",
        "if chunks_from_ds:\n",
        "  chuncked_ds = chunked_dataset['train']\n",
        "  for i in range(len(chuncked_ds)):\n",
        "      row = chuncked_ds[i]\n",
        "      chunk = row['chunk']\n",
        "      chunks_regular.append(chunk)\n",
        "      context = row['context']\n",
        "      if context:\n",
        "              chunks_with_context.append(\n",
        "                f\"{context} \\n\\n {chunk}\"\n",
        "              )\n",
        "else:\n",
        "  for doc in docs_processed:\n",
        "      for chunk in doc.chunks:\n",
        "          chunks_regular.append(chunk.text)\n",
        "          if chunk.context:  # Only include chunks that have a context\n",
        "              chunks_with_context.append(\n",
        "                f\"{chunk.context} \\n\\n {chunk.text}\"\n",
        "              )\n",
        "print(f'Len of regular chunks: {len(chunks_regular)}')\n",
        "print(f'Len of chunks with context: {len(chunks_with_context)}')\n",
        "\n",
        "\n",
        "# Now docs_processed is populated from the chunked_dataset\n",
        "# You can proceed with the rest of your code using the loaded data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX2BlkTsytEc",
        "outputId": "ca8082d0-411c-4339-e912-d872a0397d1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len of regular chunks: 882\n",
            "Len of chunks with context: 882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setiing up Indeses**"
      ],
      "metadata": {
        "id": "MZNA7MGba06b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bm25(chunks: list[str]):\n",
        "    # # Try to load existing BM25 model\n",
        "    # latest_bm25_file = get_latest_bm25_file()\n",
        "    # if latest_bm25_file:\n",
        "    #     bm25 = load_bm25_model(latest_bm25_file)\n",
        "    #     if bm25 is not None:\n",
        "    #         print(f\"Loaded existing BM25 model from {latest_bm25_file}\")\n",
        "    #         return bm25\n",
        "\n",
        "    # If no existing model found or loading failed, create a new one\n",
        "    print(\"Creating BM25 model...\")\n",
        "    tokenized_chunks = [nltk.word_tokenize(chunk) for chunk in chunks]\n",
        "    bm25 = BM25Okapi(tokenized_chunks)\n",
        "\n",
        "    # # Save the new model\n",
        "    # bm25_filename = create_filename_timestamp(\"bm25\")\n",
        "    # save_download_object(bm25, bm25_filename)\n",
        "\n",
        "    return bm25"
      ],
      "metadata": {
        "id": "_DDJMPBIziVy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "# from pinecone import ServerlessSpec\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "if not pinecone_api_key:\n",
        "  pinecone_api_key = input(\"Please enter your PINECONE API KEY: \")\n",
        "\n",
        "spec=ServerlessSpec(\n",
        "    cloud=\"aws\",\n",
        "    region=\"us-east-1\"\n",
        "  )\n",
        "\n",
        "EMBEDDING_INDEX_CONTEXTUAL: str = \"test-rag-openai-contextual\"\n",
        "EMBEDDING_INDEX_REGULAR: str = \"test-rag-openai-regular\"\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "def get_index_names(index_data):\n",
        "  \"\"\"\n",
        "  Extracts the names of indices from a list of index data.\n",
        "\n",
        "  Args:\n",
        "    index_data: A list of strings, where each string is a JSON representation of an index.\n",
        "\n",
        "  Returns:\n",
        "    A list of index names.\n",
        "  \"\"\"\n",
        "  index_names = []\n",
        "  for index_item in index_data:\n",
        "    try:\n",
        "      # index_json = json.loads(index_str)\n",
        "      index_names.append(index_item['name'])\n",
        "    except (json.JSONDecodeError, KeyError):\n",
        "      print(f\"Skipping invalid index data: {index_item}\")\n",
        "  return index_names"
      ],
      "metadata": {
        "id": "-OO6j8dxz0ej"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i-taFomMI7W"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List\n",
        "from time import sleep\n",
        "\n",
        "def wait_for_index(index_name):\n",
        "    while True:\n",
        "        desc = pc.describe_index(index_name)\n",
        "        if desc['ready']:\n",
        "            print(\"Index is ready!\")\n",
        "            break\n",
        "        sleep(5)\n",
        "\n",
        "def create_pinecone_indexes(pinecone, embedding_model, index_name: str, chunks: list[str], specs: ServerlessSpec, dimensions, index_names: List[str]) -> Any:\n",
        "\n",
        "    if index_name not in index_names:\n",
        "        pc.create_index(index_name, dimension=dimensions, metric=\"cosine\", spec=specs)\n",
        "        wait_for_index(index_name)\n",
        "\n",
        "    # Connect to Pinecone indexes\n",
        "    embedding_index = pc.Index(index_name)\n",
        "\n",
        "\n",
        "    # Semantic Embeddings using a Pre-trained Transformer Model\n",
        "    embeddings = embedding_model.embed_documents(chunks)\n",
        "    # Store embeddings in Pinecone\n",
        "    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
        "        embedding_index.upsert([(str(i), embedding, {\"text\": chunk})])\n",
        "\n",
        "    print(f'len(embeddings)={len(embeddings)}, len(embeddings[0])={len(embeddings[0])}')\n",
        "    return embedding_index\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeces =pc.list_indexes()\n",
        "print(indeces)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJwZUlQv9q0S",
        "outputId": "44391022-e693-4f0d-9dbb-5b83085a551e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\n",
            "    \"name\": \"test-rag-openai-regular\",\n",
            "    \"dimension\": 1536,\n",
            "    \"metric\": \"cosine\",\n",
            "    \"host\": \"test-rag-openai-regular-g8hsdn4.svc.aped-4627-b74a.pinecone.io\",\n",
            "    \"spec\": {\n",
            "        \"serverless\": {\n",
            "            \"cloud\": \"aws\",\n",
            "            \"region\": \"us-east-1\"\n",
            "        }\n",
            "    },\n",
            "    \"status\": {\n",
            "        \"ready\": true,\n",
            "        \"state\": \"Ready\"\n",
            "    },\n",
            "    \"deletion_protection\": \"disabled\"\n",
            "}, {\n",
            "    \"name\": \"test-rag-openai-contextual\",\n",
            "    \"dimension\": 1536,\n",
            "    \"metric\": \"cosine\",\n",
            "    \"host\": \"test-rag-openai-contextual-g8hsdn4.svc.aped-4627-b74a.pinecone.io\",\n",
            "    \"spec\": {\n",
            "        \"serverless\": {\n",
            "            \"cloud\": \"aws\",\n",
            "            \"region\": \"us-east-1\"\n",
            "        }\n",
            "    },\n",
            "    \"status\": {\n",
            "        \"ready\": true,\n",
            "        \"state\": \"Ready\"\n",
            "    },\n",
            "    \"deletion_protection\": \"disabled\"\n",
            "}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Indeses**"
      ],
      "metadata": {
        "id": "DYJD_AQ83vr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_names = get_index_names(indeces)\n",
        "print(index_names)\n",
        "if EMBEDDING_INDEX_CONTEXTUAL not in index_names:\n",
        "   create_pinecone_indexes(pc, embedding_model, EMBEDDING_INDEX_CONTEXTUAL, chunks_with_context, spec, 1536, index_names)\n",
        "if EMBEDDING_INDEX_REGULAR not in index_names:\n",
        "   create_pinecone_indexes(pc, embedding_model, EMBEDDING_INDEX_REGULAR, chunks_regular, spec, 1536, index_names)\n",
        "bm25_regular = create_bm25(chunks_regular)\n",
        "bm25_contextual = create_bm25(chunks_with_context)"
      ],
      "metadata": {
        "id": "8e7073j13uVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ce9611-9ea3-4d9e-c013-0454a7858a4d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test-rag-openai-regular', 'test-rag-openai-contextual']\n",
            "Creating BM25 model...\n",
            "Creating BM25 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Definining Reranker**"
      ],
      "metadata": {
        "id": "iU6ya_SUZcKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hugging Face**"
      ],
      "metadata": {
        "id": "V21JxTGuzFch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "RERANKER_MODEL = 'BAAI/bge-reranker-v2-m3'\n",
        "tokenizer = AutoTokenizer.from_pretrained(RERANKER_MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(RERANKER_MODEL)\n",
        "model.eval()\n",
        "\n",
        "def get_reranker_score(pairs):\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "        scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
        "        print(f'reranker scores {scores}')\n",
        "        return scores\n"
      ],
      "metadata": {
        "id": "GsB0hxSuZc6u"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FlagEmbedding**"
      ],
      "metadata": {
        "id": "_yta_ZYVzL9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from FlagEmbedding import FlagReranker\n",
        "\n",
        "# reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
        "\n",
        "# score = reranker.compute_score(['query', 'passage'])\n",
        "# print(score) # -5.65234375\n",
        "\n",
        "# # You can map the scores into 0-1 by set \"normalize=True\", which will apply sigmoid function to the score\n",
        "# score = reranker.compute_score(['query', 'passage'], normalize=True)\n",
        "# print(score) # 0.003497010252573502\n",
        "\n",
        "# scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
        "# print(scores) # [-8.1875, 5.26171875]\n",
        "\n",
        "# # You can map the scores into 0-1 by set \"normalize=True\", which will apply sigmoid function to the score\n",
        "# scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']], normalize=True)\n",
        "# print(scores) # [0.00027803096387751553, 0.9948403768236574]\n"
      ],
      "metadata": {
        "id": "NJiUX0T4wlTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "NqqB_g9TeFlW"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers import CrossEncoder\n",
        "from collections import defaultdict\n",
        "def fusion_rank_search(\n",
        "    query: str,\n",
        "    bm25,\n",
        "    chunks: list[str],\n",
        "    model,\n",
        "    embedding_index,\n",
        "    weight_sparse: float,\n",
        "    k: int = 5,\n",
        "    reranker_cutoff: int = 20  # Number of top results to rerank\n",
        "):\n",
        "    # Get BM25 results\n",
        "    tokenized_query = nltk.word_tokenize(query)\n",
        "    bm25_scores = np.array(bm25.get_scores(tokenized_query))  # Already numpy array\n",
        "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:reranker_cutoff]\n",
        "\n",
        "    # Get dense results using OpenAI embeddings\n",
        "    query_embedding = model.embed_query(query)\n",
        "\n",
        "    # Query Pinecone index\n",
        "    dense_results = embedding_index.query(\n",
        "        vector=query_embedding,\n",
        "        top_k=reranker_cutoff,\n",
        "        include_values=True\n",
        "    )\n",
        "\n",
        "    # Extract scores and indices from Pinecone results and convert to numpy arrays\n",
        "    dense_scores = np.array([match['score'] for match in dense_results['matches']])\n",
        "    dense_indices = np.array([int(match['id']) for match in dense_results['matches']])\n",
        "\n",
        "    # Normalize scores (now all operations use numpy)\n",
        "    bm25_scores_norm = (bm25_scores[bm25_top_indices] - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
        "    dense_scores_norm = (dense_scores - np.min(dense_scores)) / (np.max(dense_scores) - np.min(dense_scores))\n",
        "\n",
        "    # Create combined results\n",
        "    combined_results = {}\n",
        "\n",
        "    # Add BM25 results\n",
        "    for idx, score in zip(bm25_top_indices, bm25_scores_norm):\n",
        "        combined_results[idx] = {'score': weight_sparse * score, 'count': 1}\n",
        "\n",
        "    # Add dense results\n",
        "    for idx, score in zip(dense_indices, dense_scores_norm):\n",
        "        if idx in combined_results:\n",
        "            combined_results[idx]['score'] += (1 - weight_sparse) * score\n",
        "            combined_results[idx]['count'] += 1\n",
        "        else:\n",
        "            combined_results[idx] = {'score': (1 - weight_sparse) * score, 'count': 1}\n",
        "\n",
        "    # Calculate final scores\n",
        "    for idx in combined_results:\n",
        "        combined_results[idx]['final_score'] = combined_results[idx]['score'] / combined_results[idx]['count']\n",
        "\n",
        "    # Sort by final score\n",
        "    sorted_results = sorted(combined_results.items(), key=lambda x: x[1]['final_score'], reverse=True)\n",
        "\n",
        "    # Return top k results with their chunks\n",
        "    final_results = []\n",
        "    for idx, scores in sorted_results[:k]:\n",
        "        final_results.append({\n",
        "            'id': str(idx),\n",
        "            'score': scores['final_score'],\n",
        "            'metadata': {'text': chunks[idx]}\n",
        "        })\n",
        "\n",
        "    return final_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pE0B0-JweFlW"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_rag_system(\n",
        "    best_answers_df: pd.DataFrame,\n",
        "    bm25,\n",
        "    chunks: list[str],\n",
        "    embedding_model,\n",
        "    embedding_index,\n",
        "    llm_chain,\n",
        "    weight_sparse: float,\n",
        "    n_samples: int = None,  # Optional: limit number of samples for testing\n",
        "    reranker_cutoff: int = 20\n",
        "):\n",
        "    # Initialize ROUGE scorer\n",
        "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    # Initialize results storage\n",
        "    results = []\n",
        "\n",
        "    # Get subset of dataframe if n_samples is specified\n",
        "    eval_df = best_answers_df.head(n_samples) if n_samples else best_answers_df\n",
        "\n",
        "    # Iterate through questions and answers\n",
        "    for idx, row in tqdm(eval_df.iterrows(), total=len(eval_df), desc=\"Evaluating Questions\"):\n",
        "        query = row['question']\n",
        "        reference_answer = row['answer']\n",
        "\n",
        "        try:\n",
        "            # Get relevant context using fusion ranking\n",
        "            retrieved_results = fusion_rank_search(\n",
        "                query=query,\n",
        "                bm25=bm25,\n",
        "                chunks=chunks,\n",
        "                model=embedding_model,\n",
        "                embedding_index=embedding_index,\n",
        "                k=5,\n",
        "                weight_sparse=0.1,\n",
        "                reranker_cutoff=reranker_cutoff\n",
        "            )\n",
        "\n",
        "            # Prepare pairs for reranking\n",
        "            pairs = [(query, result['metadata']['text']) for result in retrieved_results]\n",
        "\n",
        "            # Get reranker scores - use them directly for final ranking\n",
        "            rerank_scores = get_reranker_score(pairs)\n",
        "\n",
        "            # Update results with reranker scores\n",
        "            for result, rerank_score in zip(retrieved_results, rerank_scores):\n",
        "                result['metadata']['rerank_score'] = float(rerank_score)\n",
        "                # Use reranker score as the final score\n",
        "                result['score'] = float(rerank_score)\n",
        "\n",
        "            # Resort based on reranker scores\n",
        "            retrieved_results.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "            # Prepare context for LLM\n",
        "            context = \"\\n\".join([res['metadata']['text'] for res in retrieved_results])\n",
        "\n",
        "            # Generate answer using LLM\n",
        "            llm_response = llm_chain.invoke({\n",
        "                \"context\": context,\n",
        "                \"query\": query\n",
        "            })\n",
        "            generated_answer = llm_response.content if hasattr(llm_response, 'content') else llm_response\n",
        "\n",
        "            # Calculate BLEU score\n",
        "            reference_tokens = [reference_answer.split()]\n",
        "            candidate_tokens = generated_answer.split()\n",
        "            bleu_score = sentence_bleu(reference_tokens, candidate_tokens)\n",
        "\n",
        "            # Calculate ROUGE scores\n",
        "            rouge_scores = rouge_scorer_instance.score(reference_answer, generated_answer)\n",
        "\n",
        "            # Store results\n",
        "            result = {\n",
        "                'question': query,\n",
        "                'reference_answer': reference_answer,\n",
        "                'generated_answer': generated_answer,\n",
        "                'bleu_score': bleu_score,\n",
        "                'rouge1_f1': rouge_scores['rouge1'].fmeasure,\n",
        "                'rouge2_f1': rouge_scores['rouge2'].fmeasure,\n",
        "                'rougeL_f1': rouge_scores['rougeL'].fmeasure,\n",
        "                'retrieved_contexts': [res['metadata']['text'] for res in retrieved_results],\n",
        "                'context_scores': [res['score'] for res in retrieved_results]\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question {idx}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Calculate and print average scores\n",
        "    avg_scores = {\n",
        "        'Average BLEU': results_df['bleu_score'].mean(),\n",
        "        'Average ROUGE-1': results_df['rouge1_f1'].mean(),\n",
        "        'Average ROUGE-2': results_df['rouge2_f1'].mean(),\n",
        "        'Average ROUGE-L': results_df['rouge2_f1'].mean()\n",
        "    }\n",
        "\n",
        "    return results_df, avg_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_evaluation_results(results_df, avg_scores):\n",
        "    print(\"\\nAverage Scores:\")\n",
        "    for metric, score in avg_scores.items():\n",
        "        print(f\"{metric}: {score:.4f}\")\n",
        "\n",
        "    print(\"\\nDetailed Results Sample (first 3):\")\n",
        "    for idx, row in results_df.head(3).iterrows():\n",
        "        print(\"\\nQuestion:\", row['question'])\n",
        "        print(\"Reference Answer:\", row['reference_answer'])\n",
        "        print(\"Generated Answer:\", row['generated_answer'])\n",
        "        print(f\"BLEU Score: {row['bleu_score']:.4f}\")\n",
        "        print(f\"ROUGE-1 F1: {row['rouge1_f1']:.4f}\")\n",
        "        print(f\"ROUGE-2 F1: {row['rouge2_f1']:.4f}\")\n",
        "        print(f\"ROUGE-L F1: {row['rougeL_f1']:.4f}\")\n",
        "        print(\"\\nRetrieved Contexts:\")\n",
        "        for context, score in zip(row['retrieved_contexts'], row['context_scores']):\n",
        "            print(f\"Score: {score:.4f}\")\n",
        "            print(f\"Context: {context[:200]}...\")"
      ],
      "metadata": {
        "id": "3s2MJvdRfSIu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_rag_evaluations(best_answers_df: pd.DataFrame,\n",
        "                          set1_params: dict,\n",
        "                          set2_params: dict,\n",
        "                          llm_chain,\n",
        "                          weight_sparse: float,\n",
        "                          n_samples: int = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compare RAG evaluation results between two parameter sets.\n",
        "\n",
        "    Args:\n",
        "        best_answers_df: DataFrame with questions and answers\n",
        "        set1_params: Dictionary with parameters for first evaluation\n",
        "        set2_params: Dictionary with parameters for second evaluation\n",
        "        llm_chain: The LLM chain to use for evaluation\n",
        "        n_samples: Optional number of samples to evaluate\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with comparison results\n",
        "    \"\"\"\n",
        "    # Run evaluations for both sets\n",
        "    results1_df, avg_scores1 = evaluate_rag_system(\n",
        "        best_answers_df=best_answers_df,\n",
        "        weight_sparse=weight_sparse,\n",
        "        bm25=set1_params['bm25'],\n",
        "        chunks=set1_params['chunks'],\n",
        "        embedding_model=set1_params['embedding_model'],\n",
        "        embedding_index=set1_params['embedding_index'],\n",
        "        llm_chain=llm_chain,\n",
        "        n_samples=n_samples\n",
        "    )\n",
        "\n",
        "    print_evaluation_results(results1_df, avg_scores1)\n",
        "\n",
        "    results2_df, avg_scores2 = evaluate_rag_system(\n",
        "        best_answers_df=best_answers_df,\n",
        "        weight_sparse=weight_sparse,\n",
        "        bm25=set2_params['bm25'],\n",
        "        chunks=set2_params['chunks'],\n",
        "        embedding_model=set2_params['embedding_model'],\n",
        "        embedding_index=set2_params['embedding_index'],\n",
        "        llm_chain=llm_chain,\n",
        "        n_samples=n_samples\n",
        "    )\n",
        "\n",
        "    print_evaluation_results(results2_df, avg_scores2)\n",
        "    # Create comparison DataFrame\n",
        "    comparison = pd.DataFrame({\n",
        "        'Metric': ['BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
        "        'Contextual': [\n",
        "            avg_scores1['Average BLEU'],\n",
        "            avg_scores1['Average ROUGE-1'],\n",
        "            avg_scores1['Average ROUGE-2'],\n",
        "            avg_scores1['Average ROUGE-L']\n",
        "        ],\n",
        "        'Regular': [\n",
        "            avg_scores2['Average BLEU'],\n",
        "            avg_scores2['Average ROUGE-1'],\n",
        "            avg_scores2['Average ROUGE-2'],\n",
        "            avg_scores2['Average ROUGE-L']\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # Calculate differences\n",
        "    comparison['Difference'] = comparison['Contextual'] - comparison['Regular']\n",
        "\n",
        "        # Calculate differences\n",
        "    comparison['Difference'] = comparison['Contextual'] - comparison['Regular']\n",
        "\n",
        "    # Calculate percentage difference\n",
        "    # Formula: ((new - old) / old) * 100\n",
        "    comparison['Difference %'] = ((comparison['Contextual'] - comparison['Regular']) / comparison['Regular'] * 100).round(2)\n",
        "\n",
        "    # Format numbers to 4 decimal places\n",
        "    for col in ['Contextual', 'Regular', 'Difference', 'Difference %']:\n",
        "        comparison[col] = comparison[col].round(4)\n",
        "\n",
        "    return comparison"
      ],
      "metadata": {
        "id": "5t6lgeIBfApA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_answer = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "            \"\"\"You are an AI assistant specialized in answering user queries based solely on provided context. Your primary goal is to provide clear, concise, and relevant answers without adding, making up, or hallucinating any information.\n",
        "            \"\"\"\n",
        "     ),\n",
        "    (\"human\",\"\"\"Now, consider the following context carefully:\n",
        "      <context>\n",
        "      {context}\n",
        "      </context>\n",
        "\n",
        "      Here is the user's query:\n",
        "      <query>\n",
        "      {query}\n",
        "      </query>\n",
        "\n",
        "      Before answering, please follow these steps:\n",
        "\n",
        "      1. Analyze the user's query and the provided context:\n",
        "        a. Identify the key elements of the user's query.\n",
        "        b. Find and quote relevant information from the context.\n",
        "        c. Explicitly link the quoted information to the query elements.\n",
        "        d. Formulate a potential answer based only on the context.\n",
        "        e. Explicitly check that your answer doesn't include any information not present in the context.\n",
        "        f. If the context doesn't contain enough information to answer the query, note this.\n",
        "\n",
        "      2. After your analysis process, provide your final answer or response. Do not include your analysis steps in your final answer or response, only the result.\n",
        "\n",
        "      If the context does not contain enough information to answer the user's query confidently and accurately, your final response should be: \"I do not have enough information to answer this question based on the provided context.\"\n",
        "\n",
        "      Remember, it's crucial that your answer is based entirely on the given context. Do not add any external information or make assumptions beyond what is explicitly stated in the context.\n",
        "\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "Tm9FNK8-kjSs"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def create_answer_chain(llm):\n",
        "  return prompt_template_answer | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "frqClD28mdUY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_index_contextual= pc.Index(EMBEDDING_INDEX_CONTEXTUAL)\n",
        "embedding_index_regular= pc.Index(EMBEDDING_INDEX_REGULAR)\n",
        "answer_chain = create_answer_chain(llm)"
      ],
      "metadata": {
        "id": "XGn-lZrwx1zQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "LHONc1uFeFlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c68a389-d112-4ffa-9d83-1b5258ab7ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Questions:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reranker scores tensor([ 3.2947, -4.1678, -5.7306, -4.7582, -4.7453])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Questions: 100%|██████████| 1/1 [00:32<00:00, 32.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Scores:\n",
            "Average BLEU: 0.0000\n",
            "Average ROUGE-1: 0.3077\n",
            "Average ROUGE-2: 0.0833\n",
            "Average ROUGE-L: 0.0833\n",
            "\n",
            "Detailed Results Sample (first 3):\n",
            "\n",
            "Question: What architecture is the `tokenizers-linux-x64-musl` binary designed for?\n",
            "\n",
            "Reference Answer: x86_64-unknown-linux-musl\n",
            "Generated Answer: The `tokenizers-linux-x64-musl` binary is designed for the x86_64 architecture running the musl C library on Linux systems.\n",
            "BLEU Score: 0.0000\n",
            "ROUGE-1 F1: 0.3077\n",
            "ROUGE-2 F1: 0.0833\n",
            "ROUGE-L F1: 0.2308\n",
            "\n",
            "Retrieved Contexts:\n",
            "Score: 3.2947\n",
            "Context: The chunk refers to the **x86_64-unknown-linux-musl** binary for `tokenizers`. The document focuses on the specific binary version for Linux systems, catering to the x86_64 architecture running the mu...\n",
            "Score: -4.1678\n",
            "Context: Focuses on tokenizers in natural language processing (NLP) and their role in converting text into numerical data for models to process. The chunk discusses different types of tokenization algorithms, ...\n",
            "Score: -4.7453\n",
            "Context: Focuses on the importance of tokenizers in the NLP pipeline, highlighting their role in translating text into numerical data for model processing. The chunk explains that models can only work with num...\n",
            "Score: -4.7582\n",
            "Context: The text segment focuses on a specific aspect of tokenizers in Python, detailing the components related to normalizers, pre-tokenizers, models, post-processors, and decoders. It provides a structured ...\n",
            "Score: -5.7306\n",
            "Context: - Addresses the necessity to convert raw text data into numerical data that can be processed by models, introducing the concept of tokenizers as a crucial component in natural language processing.\n",
            "- D...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Questions:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reranker scores tensor([-0.0975, -6.3564, -4.5948, -5.1581, -3.7810])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Questions: 100%|██████████| 1/1 [00:18<00:00, 18.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Scores:\n",
            "Average BLEU: 0.0000\n",
            "Average ROUGE-1: 0.0976\n",
            "Average ROUGE-2: 0.0000\n",
            "Average ROUGE-L: 0.0000\n",
            "\n",
            "Detailed Results Sample (first 3):\n",
            "\n",
            "Question: What architecture is the `tokenizers-linux-x64-musl` binary designed for?\n",
            "\n",
            "Reference Answer: x86_64-unknown-linux-musl\n",
            "Generated Answer: The context does not provide specific information about the architecture for which the `tokenizers-linux-x64-musl` binary is designed. Therefore, I do not have enough information to answer this question based on the provided context.\n",
            "BLEU Score: 0.0000\n",
            "ROUGE-1 F1: 0.0976\n",
            "ROUGE-2 F1: 0.0000\n",
            "ROUGE-L F1: 0.0976\n",
            "\n",
            "Retrieved Contexts:\n",
            "Score: -0.0975\n",
            "Context: `tokenizers-linux-x64-musl`\n",
            "\n",
            "This is the **x86_64-unknown-linux-musl** binary for `tokenizers`...\n",
            "Score: -3.7810\n",
            "Context: *Most widely-used pre-trained language models operate on sequences of tokens corresponding to word or subword units.\n",
            "Encoding text as a sequence of tokens requires a tokenizer, which is typically crea...\n",
            "Score: -4.5948\n",
            "Context: {:else}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/...\n",
            "Score: -5.1581\n",
            "Context: Components\n",
            "\n",
            "When building a Tokenizer, you can attach various types of components to\n",
            "this Tokenizer in order to customize its behavior. This page lists most\n",
            "provided components.\n",
            "\n",
            "## Normalizers\n",
            "\n",
            "A `No...\n",
            "Score: -6.3564\n",
            "Context: ## Models\n",
            "\n",
            "Models are the core algorithms used to actually tokenize, and therefore,\n",
            "they are the only mandatory component of a Tokenizer....\n",
            "| Metric   |   Contextual |   Regular |   Difference |   Difference % |\n",
            "|:---------|-------------:|----------:|-------------:|---------------:|\n",
            "| BLEU     |       0      |    0      |       0      |         nan    |\n",
            "| ROUGE-1  |       0.3077 |    0.0976 |       0.2101 |         215.38 |\n",
            "| ROUGE-2  |       0.0833 |    0      |       0.0833 |         inf    |\n",
            "| ROUGE-L  |       0.0833 |    0      |       0.0833 |         inf    |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Prepare parameter sets\n",
        "set1_params = {\n",
        "    'embedding_index': embedding_index_contextual,\n",
        "    'chunks': chunks_with_context,\n",
        "    'bm25': bm25_contextual,\n",
        "    'embedding_model': embedding_model  # Add your embedding model here\n",
        "}\n",
        "\n",
        "set2_params = {\n",
        "    'embedding_index': embedding_index_regular,\n",
        "    'chunks': chunks_regular,\n",
        "    'bm25': bm25_regular,\n",
        "    'embedding_model': embedding_model  # Add your embedding model here\n",
        "}\n",
        "\n",
        "# Run comparison\n",
        "comparison_results = compare_rag_evaluations(\n",
        "    best_answers_df=best_answers_df,\n",
        "    weight_sparse=0.2,\n",
        "    set1_params=set1_params,\n",
        "    set2_params=set2_params,\n",
        "    llm_chain=answer_chain,\n",
        "    n_samples=1  # Set to a number if you want to limit samples\n",
        ")\n",
        "\n",
        "# Display results as markdown table\n",
        "print(comparison_results.to_markdown(index=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5DsTq5PfB65i",
        "-VTES-HCnx5m",
        "NZPBwmbjThSx",
        "mQXquYWATr5Z"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7610eb823dcb447b83c1f07d4e922c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95ea3550d20f45b7a2402f59fd581e34",
              "IPY_MODEL_ee9778ad21a14bfa92223cb6de4741b5",
              "IPY_MODEL_b81a5e87e001431a926539b99bfab218"
            ],
            "layout": "IPY_MODEL_df87fa25688b4ad0b72118ce661eac05"
          }
        },
        "95ea3550d20f45b7a2402f59fd581e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76a99c20f17841fab64199faa2002154",
            "placeholder": "​",
            "style": "IPY_MODEL_bb4c39c9a41c496498865e7f68924b77",
            "value": "model.safetensors: 100%"
          }
        },
        "ee9778ad21a14bfa92223cb6de4741b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee0a3d7436d4e7190213edbdb9c897f",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed39c1c722d64fec8d89adadc72f6567",
            "value": 90868376
          }
        },
        "b81a5e87e001431a926539b99bfab218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50fd9a4eea954b5d9c75ed91ad4a89d6",
            "placeholder": "​",
            "style": "IPY_MODEL_70584dbd70df495cb79be133338b14ba",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 90.1MB/s]"
          }
        },
        "df87fa25688b4ad0b72118ce661eac05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a99c20f17841fab64199faa2002154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb4c39c9a41c496498865e7f68924b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fee0a3d7436d4e7190213edbdb9c897f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed39c1c722d64fec8d89adadc72f6567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50fd9a4eea954b5d9c75ed91ad4a89d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70584dbd70df495cb79be133338b14ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9241444d88c844e2a97676d935765b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14071b0512b94c3181e53db7b3a35202",
              "IPY_MODEL_88582e22f86944e8a9d2e7dc853faf04",
              "IPY_MODEL_a12cc0c4e5884849b2e444a6d0b4406b"
            ],
            "layout": "IPY_MODEL_bf8c9017c3184fb2866cc648214ed5ca"
          }
        },
        "14071b0512b94c3181e53db7b3a35202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9fc53cbd414753a7fa4043889b70d9",
            "placeholder": "​",
            "style": "IPY_MODEL_54f70b15dbef48ee965499b73b3ab6e6",
            "value": "Uploading the dataset shards: 100%"
          }
        },
        "88582e22f86944e8a9d2e7dc853faf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a17c06c44aa47968f7a53b27c6629c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8c018602232414f8b11f582f0f521d6",
            "value": 1
          }
        },
        "a12cc0c4e5884849b2e444a6d0b4406b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a81a45162774028a2f354c7dc01db9c",
            "placeholder": "​",
            "style": "IPY_MODEL_591704ad35224966b086db29df777f07",
            "value": " 1/1 [00:00&lt;00:00,  1.78it/s]"
          }
        },
        "bf8c9017c3184fb2866cc648214ed5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9fc53cbd414753a7fa4043889b70d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f70b15dbef48ee965499b73b3ab6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a17c06c44aa47968f7a53b27c6629c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c018602232414f8b11f582f0f521d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a81a45162774028a2f354c7dc01db9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591704ad35224966b086db29df777f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbfc32869ed4774a7f6ccc10b27c5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f38a0ff551b24dfc8ebc98ec9b0666eb",
              "IPY_MODEL_81773f9406fa4975ad238e82357e1b89",
              "IPY_MODEL_86ddfc36ed5b4999a8c908eee6096754"
            ],
            "layout": "IPY_MODEL_3e5a5f41c3144d36853ed4d1b68544c5"
          }
        },
        "f38a0ff551b24dfc8ebc98ec9b0666eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ed6f3b38503478e9cf614c8a17702c5",
            "placeholder": "​",
            "style": "IPY_MODEL_1cbb00e355c94d5a976b27a138cba919",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "81773f9406fa4975ad238e82357e1b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3b0e6739024d639b47428237c7db24",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_788b2295dbe540728fa17fd58b6725dc",
            "value": 1
          }
        },
        "86ddfc36ed5b4999a8c908eee6096754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad2f57aab3c456f8e83ca4a7c619787",
            "placeholder": "​",
            "style": "IPY_MODEL_e4d679ad02d9456badd82efe18b50f57",
            "value": " 1/1 [00:00&lt;00:00, 20.14ba/s]"
          }
        },
        "3e5a5f41c3144d36853ed4d1b68544c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed6f3b38503478e9cf614c8a17702c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cbb00e355c94d5a976b27a138cba919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd3b0e6739024d639b47428237c7db24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788b2295dbe540728fa17fd58b6725dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cad2f57aab3c456f8e83ca4a7c619787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d679ad02d9456badd82efe18b50f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5602a797be045b6a025b732d7fd4239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_207784568862475286a2937769378f6d",
              "IPY_MODEL_c1ad258a0ad24635b10c464550fe3e4f",
              "IPY_MODEL_7664336b406b4551b5b6d286de592dbc"
            ],
            "layout": "IPY_MODEL_f4483a2dbaad421cbe785820d3b0c7bd"
          }
        },
        "207784568862475286a2937769378f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9160ea16bd64a108bcd94aa8836ae67",
            "placeholder": "​",
            "style": "IPY_MODEL_f5e531602d164991b20168d360c2819f",
            "value": "README.md: 100%"
          }
        },
        "c1ad258a0ad24635b10c464550fe3e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c7c09ea507436eb3bb8b58d5389df6",
            "max": 893,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d127fc274474d96ab3b8f0f46d5ec2d",
            "value": 893
          }
        },
        "7664336b406b4551b5b6d286de592dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d8e28fb7664439a99f3b4a7b062206",
            "placeholder": "​",
            "style": "IPY_MODEL_63fbd3b86956469080dd49892c5ac715",
            "value": " 893/893 [00:00&lt;00:00, 23.8kB/s]"
          }
        },
        "f4483a2dbaad421cbe785820d3b0c7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9160ea16bd64a108bcd94aa8836ae67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e531602d164991b20168d360c2819f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6c7c09ea507436eb3bb8b58d5389df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d127fc274474d96ab3b8f0f46d5ec2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43d8e28fb7664439a99f3b4a7b062206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fbd3b86956469080dd49892c5ac715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ee735a3c0024663b3adc611163f8a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f29b4582df454f1cad766a147095fbb1",
              "IPY_MODEL_1c4075de3c47470b933a194b937c5ac1",
              "IPY_MODEL_6ab140d7c2fd4cf6ae7c1c0347d4cbe8"
            ],
            "layout": "IPY_MODEL_a9507383300d447fadd2884d8086461e"
          }
        },
        "f29b4582df454f1cad766a147095fbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8e4d9b8b5043769baed08283ff81c8",
            "placeholder": "​",
            "style": "IPY_MODEL_6e18cbcd4dc046d4b1a97215e5d95d4d",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "1c4075de3c47470b933a194b937c5ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880c9a3f43ed496bb78bd607904a7803",
            "max": 289016,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_127d4ef074b94b7e99fd631d9d0ea851",
            "value": 289016
          }
        },
        "6ab140d7c2fd4cf6ae7c1c0347d4cbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36275140a3dc423a803dc375cf7eac52",
            "placeholder": "​",
            "style": "IPY_MODEL_a2da143390f44e8aa91332046a2ee884",
            "value": " 289k/289k [00:00&lt;00:00, 3.41MB/s]"
          }
        },
        "a9507383300d447fadd2884d8086461e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8e4d9b8b5043769baed08283ff81c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e18cbcd4dc046d4b1a97215e5d95d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880c9a3f43ed496bb78bd607904a7803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127d4ef074b94b7e99fd631d9d0ea851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36275140a3dc423a803dc375cf7eac52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2da143390f44e8aa91332046a2ee884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07527b16c8ca4526b5bfdcd3ee8ad281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec11416e51a84a328fc29c2fdcab07d6",
              "IPY_MODEL_4d9567829d3b4bf7a0deaca711211a95",
              "IPY_MODEL_93efcf19123141289c2ea18cc021bfc2"
            ],
            "layout": "IPY_MODEL_3ac2644a564a48549a060daae0f43461"
          }
        },
        "ec11416e51a84a328fc29c2fdcab07d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0c5d0d19954f01b133b0fc03dc203d",
            "placeholder": "​",
            "style": "IPY_MODEL_f154d84958824a2289caef700fc4b976",
            "value": "Generating train split: 100%"
          }
        },
        "4d9567829d3b4bf7a0deaca711211a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35936cdb3f93494b836647bbf828f9c1",
            "max": 65,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62652df54c6f4e88a31e2c63e5f2d085",
            "value": 65
          }
        },
        "93efcf19123141289c2ea18cc021bfc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5640b1fa1bee41dfac05d91d1b5ae42c",
            "placeholder": "​",
            "style": "IPY_MODEL_fc67f480e43e45adaec8828a5c43a521",
            "value": " 65/65 [00:00&lt;00:00, 731.54 examples/s]"
          }
        },
        "3ac2644a564a48549a060daae0f43461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0c5d0d19954f01b133b0fc03dc203d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f154d84958824a2289caef700fc4b976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35936cdb3f93494b836647bbf828f9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62652df54c6f4e88a31e2c63e5f2d085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5640b1fa1bee41dfac05d91d1b5ae42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc67f480e43e45adaec8828a5c43a521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8702996f07724f8db48ea84ccb75bc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c475b51eaf94f38b47807c24ad4474d",
              "IPY_MODEL_6db74a9354d64ca0b7cdf9f5739fed75",
              "IPY_MODEL_e8af6213dd9f4384ba8abd36ce43797e"
            ],
            "layout": "IPY_MODEL_3982f06b62c24f93b7c5c955d779a5c1"
          }
        },
        "0c475b51eaf94f38b47807c24ad4474d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e9ad3287864c1da32ecfd9eb8c599c",
            "placeholder": "​",
            "style": "IPY_MODEL_6b709b9213ae4c82908b54a9258a2c96",
            "value": "README.md: 100%"
          }
        },
        "6db74a9354d64ca0b7cdf9f5739fed75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c5487a349e43f79eb8d4de576bb9eb",
            "max": 348,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23529e6fc5304298bb1573272cd06c6c",
            "value": 348
          }
        },
        "e8af6213dd9f4384ba8abd36ce43797e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e57e462062de41d69c07e180ba4261f2",
            "placeholder": "​",
            "style": "IPY_MODEL_2416240337ff450a964ef2f153782483",
            "value": " 348/348 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "3982f06b62c24f93b7c5c955d779a5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e9ad3287864c1da32ecfd9eb8c599c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b709b9213ae4c82908b54a9258a2c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0c5487a349e43f79eb8d4de576bb9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23529e6fc5304298bb1573272cd06c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e57e462062de41d69c07e180ba4261f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2416240337ff450a964ef2f153782483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32c58fa32a2840e4914134434c37b665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_482fc3846d4d4eb39e5f95d98f53f61b",
              "IPY_MODEL_23d1f1fee552402498202007d6256778",
              "IPY_MODEL_ae5e640938e04d3d8e0d705992d3693d"
            ],
            "layout": "IPY_MODEL_78676885d1b6420e88076e78c2dfd32c"
          }
        },
        "482fc3846d4d4eb39e5f95d98f53f61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09aa0733f352465599c98e2dd7406527",
            "placeholder": "​",
            "style": "IPY_MODEL_1b9aec97b3d24cb7a8dae21d9b7b268d",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "23d1f1fee552402498202007d6256778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce4e81ca5fbd41fe9cbf7245a7d59911",
            "max": 658578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c54dcff8598c4592a4abf10b9aec62cf",
            "value": 658578
          }
        },
        "ae5e640938e04d3d8e0d705992d3693d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c1618d4772498d8b0ecdf912dea553",
            "placeholder": "​",
            "style": "IPY_MODEL_32a48a35a83841f58fb12740c24ed46e",
            "value": " 659k/659k [00:00&lt;00:00, 2.29MB/s]"
          }
        },
        "78676885d1b6420e88076e78c2dfd32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09aa0733f352465599c98e2dd7406527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9aec97b3d24cb7a8dae21d9b7b268d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce4e81ca5fbd41fe9cbf7245a7d59911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54dcff8598c4592a4abf10b9aec62cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1c1618d4772498d8b0ecdf912dea553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a48a35a83841f58fb12740c24ed46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f893a601d4254cf18767503126dbafb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471d533d1b6e4e5a98c61259dec39445",
              "IPY_MODEL_c916d773283d4b558fd3201c5f9346eb",
              "IPY_MODEL_1b9b6a37b02f480fb09dfc354010aafb"
            ],
            "layout": "IPY_MODEL_bc2f5660010a4c109254e18c39b5c818"
          }
        },
        "471d533d1b6e4e5a98c61259dec39445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a62108eaaf74204bbf6f5f46c337577",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec8c6fc4fd94f1785a991a485908f45",
            "value": "Generating train split: 100%"
          }
        },
        "c916d773283d4b558fd3201c5f9346eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098c36a685594b859e83e3b3e094ddde",
            "max": 882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76072dfd0ad94175b53234ce8b40f229",
            "value": 882
          }
        },
        "1b9b6a37b02f480fb09dfc354010aafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12aa1dbf3ee7428e974f8cb890487af0",
            "placeholder": "​",
            "style": "IPY_MODEL_4175c196332a4f74abb57e2899a62fdc",
            "value": " 882/882 [00:00&lt;00:00, 10760.38 examples/s]"
          }
        },
        "bc2f5660010a4c109254e18c39b5c818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a62108eaaf74204bbf6f5f46c337577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec8c6fc4fd94f1785a991a485908f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "098c36a685594b859e83e3b3e094ddde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76072dfd0ad94175b53234ce8b40f229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12aa1dbf3ee7428e974f8cb890487af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4175c196332a4f74abb57e2899a62fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}